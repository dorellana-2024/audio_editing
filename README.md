# ğŸ§ Audio Diarization Project (pyannote.audio)

Proyecto para diarizaciÃ³n de hablantes usando pyannote.audio y modelos de Hugging Face, orientado a procesamiento de audio infantil/adulto en archivos .wav.

## ğŸ“Œ DescripciÃ³n

Este proyecto utiliza el pipeline pyannote/speaker-diarization-3.0 para:
- detectar segmentos de voz
- identificar hablantes distintos
- preparar el audio para cortes posteriores

EstÃ¡ configurado para funcionar correctamente en Windows, evitando problemas comunes con:
- symlinks
- permisos
- versiones incompatibles de Torch / Pyannote

## ğŸ§± Requisitos del sistema

- Windows 10 / 11
- Python 3.10.11
- Git
- Cuenta en Hugging Face con acceso a modelos pyannote/
- FFmpeg instalado y disponible en PATH
    - https://www.gyan.dev/ffmpeg/builds/
    - Download: ffmpeg-release-essentials.zip

## ğŸ Entorno virtual

Crear entorno virtual
```bash
py -3.10 -m venv venv
```
Activar entorno
```bash
venv\Scripts\activate
```
Verificar:
```bash
python --version
# Python 3.10.11
```

## ğŸ“¦ Dependencias
```txt
# requirements.in
pyannote.audio==3.1.1
torch==2.1.2
torchaudio==2.1.2

onnxruntime==1.16.3

pydub
numpy<2.0

ipywidgets>=8,<9
python-dotenv>=1.0.0,<2.0
huggingface-hub==0.19.4
```

Instalar dependencias

```bash
pip install --upgrade pip
pip install pip-tools
pip-compile requirements.in
pip install -r requirements.txt
```

ğŸ’¡ requirements.txt debe generarse con pip-compile si se usa pip-tools.

## ğŸ” Token de Hugging Face

1. Crear token

ğŸ‘‰ https://huggingface.co/settings/tokens

Permisos necesarios: READ

2. Aceptar modelos (una sola vez)
- https://huggingface.co/pyannote/speaker-diarization-3.0
- https://huggingface.co/pyannote/segmentation-3.0

Debe decir:
âœ… You have been granted access to this model

## ğŸŒ± Variables de entorno

Crear archivo .env en la raÃ­z del proyecto:

```.env
PYANNOTE_HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx
```

## ğŸ§  CÃ³digo base (main.ipynb)
```py
import os

# --- Windows / Hugging Face fixes ---
os.environ["HF_HUB_DISABLE_SYMLINKS"] = "1"
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
os.environ["SPEECHBRAIN_CACHE_STRATEGY"] = "copy"

from dotenv import load_dotenv
from pydub import AudioSegment
from pyannote.audio import Pipeline

# Widgets (opcional, Jupyter)
import ipywidgets as widgets
widgets.IntSlider()

# Load env variables
load_dotenv()

HF_TOKEN = os.getenv("PYANNOTE_HF_TOKEN")
assert HF_TOKEN, "PYANNOTE_HF_TOKEN not defined."

# Load diarization pipeline
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-3.0",
    use_auth_token=HF_TOKEN
)
```

## âš ï¸ Advertencias esperadas (NO errores)

```terminal
UserWarning: torchaudio._backend.get_audio_backend has been deprecated
UserWarning: speechbrain.pretrained was deprecated
UserWarning: AudioMetaData has been moved
```

## ğŸ§¹ Estructura del proyecto
```txt
audio_editing/
â”‚
â”œâ”€ notebooks/
â”‚   â””â”€ main.ipynb
â”‚
â”œâ”€ audios/
â”‚   â””â”€ input.wav
â”‚
â”œâ”€ output/
â”‚
â”œâ”€ .env
â”œâ”€ requirements.in
â”œâ”€ requirements.txt
â”œâ”€ README.md
â””â”€ venv_py3.10/
```
